{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import bisect\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.ndimage\n",
    "import scipy.misc\n",
    "\n",
    "import config\n",
    "import misc\n",
    "import tfutil\n",
    "import train\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Age Progression\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'age_progression_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        latents = latents[0:int(len(latents)/6),:] ####\n",
    "        latents = np.tile(latents, [6, 1])\n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:2] = [0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        labels[2:4] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "        labels[4:6] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        labels[6:8] = [1,0,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1] #### 000051\n",
    "        labels[int(latents.shape[0]/6):int(latents.shape[0]/6)*2] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/6)*2:int(latents.shape[0]/6)*3] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/6)*3:int(latents.shape[0]/6)*4] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/6)*4:int(latents.shape[0]/6)*5] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/6)*5:int(latents.shape[0]/6)*6] = labels[0:8]\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blond hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "        \n",
    "        labels[int(latents.shape[0]/6):int(latents.shape[0]/6)*2,16] = 0.8\n",
    "        labels[int(latents.shape[0]/6):int(latents.shape[0]/6)*2,9] = 0.2\n",
    "        labels[int(latents.shape[0]/6)*2:int(latents.shape[0]/6)*3,16] = 0.6\n",
    "        labels[int(latents.shape[0]/6)*2:int(latents.shape[0]/6)*3,9] = 0.4\n",
    "        labels[int(latents.shape[0]/6)*3:int(latents.shape[0]/6)*4,16] = 0.4\n",
    "        labels[int(latents.shape[0]/6)*3:int(latents.shape[0]/6)*4,9] = 0.6\n",
    "        labels[int(latents.shape[0]/6)*4:int(latents.shape[0]/6)*5,16] = 0.2\n",
    "        labels[int(latents.shape[0]/6)*4:int(latents.shape[0]/6)*5,9] = 0.8\n",
    "        labels[int(latents.shape[0]/6)*5:int(latents.shape[0]/6)*6,16] = 0\n",
    "        labels[int(latents.shape[0]/6)*5:int(latents.shape[0]/6)*6,9] = 1\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[8,6];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Age Comparison\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'age_comparison_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        latents = latents[0:int(len(latents)/4),:] ####\n",
    "        latents = np.tile(latents, [4, 1])\n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:2] = [0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        labels[2:4] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "        labels[4:6] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        labels[6:8] = [1,0,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1] #### 000051\n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4] = labels[0:8]\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blond hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "        \n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2,16] = 0\n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2,9] = 0\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3,16] = 1\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3,9] = 1\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4,16] = 0\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4,9] = 1\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[8,4];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hair Progression\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'hair_color_progression_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        latents = latents[0:int(len(latents)/5),:] ####\n",
    "        latents = np.tile(latents, [5, 1])\n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:2] = [0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        labels[2:4] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "        labels[4:6] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        labels[6:8] = [0,0,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0] #### 000052\n",
    "        labels[int(latents.shape[0]/5):int(latents.shape[0]/5)*2] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/5)*2:int(latents.shape[0]/5)*3] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/5)*3:int(latents.shape[0]/5)*4] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/5)*4:int(latents.shape[0]/5)*5] = labels[0:8]\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "        \n",
    "        labels[int(latents.shape[0]/5):int(latents.shape[0]/5)*2,4:7] = [1, 0, 0]\n",
    "        labels[int(latents.shape[0]/5):int(latents.shape[0]/5)*2,9] = 0\n",
    "        labels[int(latents.shape[0]/5)*2:int(latents.shape[0]/5)*3,4:7] = [0, 1, 0]\n",
    "        labels[int(latents.shape[0]/5)*2:int(latents.shape[0]/5)*3,9] = 0\n",
    "        labels[int(latents.shape[0]/5)*3:int(latents.shape[0]/5)*4,4:7] = [0, 0, 1]\n",
    "        labels[int(latents.shape[0]/5)*3:int(latents.shape[0]/5)*4,9] = 0\n",
    "        labels[int(latents.shape[0]/5)*4:int(latents.shape[0]/5)*5,4:7] = [0, 0, 0]\n",
    "        labels[int(latents.shape[0]/5)*4:int(latents.shape[0]/5)*5,9] = 1\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[8,5];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TensorFlow...\n",
      "Loading network from \"results/063-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-006467.pkl\"...\n",
      "Saving results to report_results/052-beard_progression_63_6467\n",
      "Generating png 0 / 1...\n"
     ]
    }
   ],
   "source": [
    "##beard_progression\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'beard_progression_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        latents = latents[0:int(len(latents)/4),:] ####\n",
    "        latents = np.tile(latents, [4, 1])\n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:3] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        labels[3:6] = [1,0,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0] #### 000051\n",
    "        labels[6:9] = [0,0,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0] #### 000052\n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2] = labels[0:9]\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3] = labels[0:9]\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4] = labels[0:9]\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "        \n",
    "        labels[0:9,12] = 1\n",
    "        labels[0:9,0] = 0\n",
    "        labels[0:9,8] = 0\n",
    "        labels[0:9,11] = 0\n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2,0] = 2\n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2,12] = 0\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3,8] = 2\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3,12] = 0\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4,11] = 2\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4,12] = 0\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[9,4];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##eyeglasses, hat, bangs\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'eyeglasses_hat_bangs_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        latents = latents[0:int(len(latents)/4),:] ####\n",
    "        latents = np.tile(latents, [4, 1])\n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:2] = [0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        labels[2:4] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "        labels[4:6] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        labels[6:8] = [0,0,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0] #### 000052\n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3] = labels[0:8]\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4] = labels[0:8]\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "        \n",
    "        labels[int(latents.shape[0]/4):int(latents.shape[0]/4)*2,3] = 1\n",
    "        labels[int(latents.shape[0]/4)*2:int(latents.shape[0]/4)*3,7] = 1\n",
    "        labels[int(latents.shape[0]/4)*3:int(latents.shape[0]/4)*4,15] = 1\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[8,4];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##User Report\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'User Report_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        latents = latents[0:int(len(latents)/2),:] ####\n",
    "        latents = np.tile(latents, [2, 1])\n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        #labels[0] = [0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        #labels[0:3] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "        labels[0:3] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        #labels[1] = [0,0,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0] #### 000052\n",
    "        labels[3:6] = labels[0:3]\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "        \n",
    "        #labels[3:6,4] = 0\n",
    "        #labels[3:6,5] = 1\n",
    "        #labels[3:6,0] = 0\n",
    "        labels[3:6,16] = 0\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[3,2];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TensorFlow...\n",
      "Loading network from \"results/063-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-006467.pkl\"...\n",
      "Saving results to report_results/059-Random_Images_63_6467\n",
      "Generating png 0 / 1...\n"
     ]
    }
   ],
   "source": [
    "##Random Images\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'Random_Images_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:3] = [0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        labels[3:6] = [1,0,0,0,1,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0] #### 000051\n",
    "        labels[6:9] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "        labels[9:12] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "        labels[12:15] = [0,0,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0] #### 000052\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "\n",
    "        \n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[3,5];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TensorFlow...\n",
      "Loading network from \"results/063-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-006467.pkl\"...\n",
      "Saving results to report_results/082-More_Random_Images_63_6467\n",
      "Generating png 0 / 1...\n"
     ]
    }
   ],
   "source": [
    "## more random images\n",
    "def generate_fake_images(labels ,run_id=63, snapshot=6467, grid_size=[1,1], num_pngs=1, image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    network_pkl = misc.locate_network_pkl(run_id, snapshot)\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, snapshot)\n",
    "\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'More_Random_Images_'+str(run_id)+'_'+str(snapshot))\n",
    "    for png_idx in range(num_pngs):\n",
    "        print('Generating png %d / %d...' % (png_idx, num_pngs))\n",
    "        latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "        labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "        labels[0:np.prod(grid_size)] = [0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "        \n",
    "        new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "        new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "        new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "        new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "        new_labels[:,6] = labels[:,11] #brown_hair\n",
    "        new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "        new_labels[:,10] = labels[:,20] #male\n",
    "        new_labels[:,11] = labels[:,22] #mustache\n",
    "        new_labels[:,12] = labels[:,24] #no_beard\n",
    "        new_labels[:,13] = labels[:,30] #side_burns\n",
    "        new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "        new_labels[:,15] = labels[:,35] #hat\n",
    "        new_labels[:,16] = labels[:,39] #young\n",
    "        labels = new_labels\n",
    "\n",
    "        labels[0:int(latents.shape[0]/8),:] = [0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0] #female, wavy, bangs, gray hair, old\n",
    "        labels[int(latents.shape[0]/8):int(latents.shape[0]/8)*2,:] = [1,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,1]  #male, 5 oclock shadow, bangs, wavy, blonde hair, young\n",
    "        labels[int(latents.shape[0]/8)*2:int(latents.shape[0]/8)*3,:] = [1,0,0,0,1,0,0,1,2,0,1,0,0,0,1,0,1] #male, 5 oclock shadow, goatee, black hair, straight hair, eye glasses, young\n",
    "        labels[int(latents.shape[0]/8)*3:int(latents.shape[0]/8)*4,:] = [0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1] #female, blonde hair, wavy hair, young\n",
    "        labels[int(latents.shape[0]/8)*4:int(latents.shape[0]/8)*5,:] = [0,0,0,1,1,0,0,1,0,0,0,0,1,0,1,0,1] #female, black hair, bangs, straight hair, young, eye glasses\n",
    "        labels[int(latents.shape[0]/8)*5:int(latents.shape[0]/8)*6,:] = [0,0,1,0,0,0,0,0,0,1,1,2,0,0,0,0,0] #male, bald, gray hair, mustach, old\n",
    "        labels[int(latents.shape[0]/8)*6:int(latents.shape[0]/8)*7,:] = [0,0,0,0,0,0,1,0,1,0,1,0,0,0,1,0,1] #male, brown hair, goatee, straight hair, young\n",
    "        labels[int(latents.shape[0]/8)*7:int(latents.shape[0]/8)*8,:] = [0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1]  #female, brown hair, straight hair, young\n",
    "\n",
    "        images = Gs.run(latents, labels, minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, png_idx)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[9,8];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_id, snapshot=6467, grid_size = grid_size, random_seed=1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TensorFlow...\n",
      "Saving results to report_results/087-training_progression\n",
      "Loading network from \"results/058-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-000160.pkl\"...\n",
      "Loading network from \"results/058-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-001462.pkl\"...\n",
      "Loading network from \"results/058-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-002826.pkl\"...\n",
      "Loading network from \"results/058-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-003547.pkl\"...\n",
      "Loading network from \"results/058-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-004227.pkl\"...\n",
      "Loading network from \"results/058-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-004947.pkl\"...\n",
      "Loading network from \"results/060-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-005827.pkl\"...\n",
      "Loading network from \"results/063-pgan-celeba-cond-preset-v2-1gpu-fp32-GRAPH/network-snapshot-006467.pkl\"...\n"
     ]
    }
   ],
   "source": [
    "## progression through training\n",
    "def generate_fake_images(labels ,run_ids_snapshots=[[63,6467]], grid_size=[1,1], image_shrink=1, png_prefix=None, random_seed=1000, minibatch_size=8):\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "    result_subdir = misc.create_result_subdir('report_results', 'training_progression')\n",
    "    images = np.zeros([np.prod(grid_size),3,64,64])\n",
    "    \n",
    "    network_pkl = misc.locate_network_pkl(run_ids_snapshots[0][0], run_ids_snapshots[0][1])\n",
    "    if png_prefix is None:\n",
    "        png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "    print('Loading network from \"%s\"...' % network_pkl)\n",
    "    G, D, Gs = misc.load_network_pkl(network_pkl, run_ids_snapshots[0][1])\n",
    "    \n",
    "    latents = misc.random_latents(np.prod(grid_size), Gs, random_state=random_state) \n",
    "    latents = latents[0:int(len(latents)/8),:] ####\n",
    "    latents = np.tile(latents, [8, 1])\n",
    "    labels = np.zeros([latents.shape[0], 40], np.float32)\n",
    "    labels[0] = [0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1] #### 000002\n",
    "    labels[1] = [1,0,0,0,1,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0] #### 000051\n",
    "    labels[2] = [1,0,1,1,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1] #### 000007\n",
    "    labels[3] = [0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,1] #### 000006\n",
    "    labels[4] = [0,0,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0] #### 000052\n",
    "    labels[int(latents.shape[0]/8):int(latents.shape[0]/8)*2] = labels[0:5]\n",
    "    labels[int(latents.shape[0]/8)*2:int(latents.shape[0]/8)*3] = labels[0:5]\n",
    "    labels[int(latents.shape[0]/8)*3:int(latents.shape[0]/8)*4] = labels[0:5]\n",
    "    labels[int(latents.shape[0]/8)*4:int(latents.shape[0]/8)*5] = labels[0:5]\n",
    "    labels[int(latents.shape[0]/8)*5:int(latents.shape[0]/8)*6] = labels[0:5]\n",
    "    labels[int(latents.shape[0]/8)*6:int(latents.shape[0]/8)*7] = labels[0:5]\n",
    "    labels[int(latents.shape[0]/8)*7:int(latents.shape[0]/8)*8] = labels[0:5]\n",
    "    \n",
    "    new_labels = np.zeros((labels.shape[0],17), dtype=np.float32);\n",
    "    new_labels[:,0] = labels[:,0] #5_oclock_shadow\n",
    "    new_labels[:,1:4] = labels[:,3:6] #wavy_hair, Bald, Bangs\n",
    "    new_labels[:,4:6] = labels[:,8:10] #black_hair, blonde hair\n",
    "    new_labels[:,6] = labels[:,11] #brown_hair\n",
    "    new_labels[:,7:10] = labels[:,15:18] #Eyeglasses, goatee, gray_hair\n",
    "    new_labels[:,10] = labels[:,20] #male\n",
    "    new_labels[:,11] = labels[:,22] #mustache\n",
    "    new_labels[:,12] = labels[:,24] #no_beard\n",
    "    new_labels[:,13] = labels[:,30] #side_burns\n",
    "    new_labels[:,14] = labels[:,32] #straigth_hair\n",
    "    new_labels[:,15] = labels[:,35] #hat\n",
    "    new_labels[:,16] = labels[:,39] #young\n",
    "    labels = new_labels\n",
    "    \n",
    "    images[0:8] = Gs.run(latents[0:8], labels[0:8], minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "    \n",
    "    for i in range(1,8):\n",
    "        network_pkl = misc.locate_network_pkl(run_ids_snapshots[i][0], run_ids_snapshots[i][1])\n",
    "        if png_prefix is None:\n",
    "            png_prefix = misc.get_id_string_for_network_pkl(network_pkl) + '-'\n",
    "        print('Loading network from \"%s\"...' % network_pkl)\n",
    "        G, D, Gs = misc.load_network_pkl(network_pkl, run_ids_snapshots[i][1])\n",
    "        images[i*8:(i+1)*8] = Gs.run(latents[i*8:(i+1)*8], labels[i*8:(i+1)*8], minibatch_size=minibatch_size, num_gpus=config.num_gpus, out_mul=127.5, out_add=127.5, out_shrink=image_shrink, out_dtype=np.uint8)\n",
    "        \n",
    "    misc.save_image_grid(images, os.path.join(result_subdir, '%s%06d.png' % (png_prefix, 0)), [0,255], grid_size)\n",
    "    open(os.path.join(result_subdir, '_done.txt'), 'wt').close()\n",
    "\n",
    "run_id = 63\n",
    "grid_size=[5,8];\n",
    "num_pngs=1\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "np.random.seed(config.random_seed)\n",
    "labels = []\n",
    "print('Initializing TensorFlow...')\n",
    "os.environ.update(config.env)\n",
    "tfutil.init_tf(config.tf_config)\n",
    "generate_fake_images(labels, run_ids_snapshots = [[58,160],[58,1462],[58,2826],[58,3547],[58,4227],[58,4947],[60,5827],[63,6467]], grid_size = grid_size, random_seed=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
